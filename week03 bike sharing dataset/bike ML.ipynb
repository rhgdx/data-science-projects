{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as numpy\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../week03/data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../week03/data/train.csv', parse_dates=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['day']= df['datetime'].dt.day\n",
    "df['hour'] = df['datetime'].dt.hour\n",
    "df['month'] = df['datetime'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this was actually close to what I initially wrote, but elegant, in theory you should do this on train and test if submitting to kaggle\n",
    "df.loc[df['weather']==4, 'weather'] = 3\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "weather\n",
       "1    7192\n",
       "2    2834\n",
       "3     860\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['weather'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import (train_test_split, cross_val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['count'] # this is the dv\n",
    "X = df.drop(['count', 'registered', 'casual', 'atemp'],  axis =1) #this now separates the DV to prevent data leakage, there is argument about registered and casual being data leak or not\n",
    "#though I will say having them boosts my score like 25% on the linear regression\n",
    "#atemp had no effect to at least 3 digits on my linear regression scores\n",
    "# X = df.drop(['atemp', ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def reduc_weather(df):\n",
    " #   return df.replace({4:3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2011-01-01 00:00:00\n",
       "1       2011-01-01 01:00:00\n",
       "2       2011-01-01 02:00:00\n",
       "3       2011-01-01 03:00:00\n",
       "4       2011-01-01 04:00:00\n",
       "                ...        \n",
       "10881   2012-12-19 19:00:00\n",
       "10882   2012-12-19 20:00:00\n",
       "10883   2012-12-19 21:00:00\n",
       "10884   2012-12-19 22:00:00\n",
       "10885   2012-12-19 23:00:00\n",
       "Name: datetime, Length: 10886, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['datetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard xtrain y train for sklearn\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, random_state=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer  \n",
    "# turn categorical values into binary columns, ordinal, bins, and scales\n",
    "from sklearn.preprocessing import (OneHotEncoder, OrdinalEncoder, KBinsDiscretizer, MinMaxScaler, StandardScaler, PolynomialFeatures)\n",
    "#column transform\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import (LinearRegression, Lasso, Ridge, ElasticNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3738</th>\n",
       "      <td>2011-09-06 17:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>22.14</td>\n",
       "      <td>88</td>\n",
       "      <td>26.0027</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3991</th>\n",
       "      <td>2011-09-17 08:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>18.86</td>\n",
       "      <td>77</td>\n",
       "      <td>16.9979</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8608</th>\n",
       "      <td>2012-08-01 01:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27.06</td>\n",
       "      <td>83</td>\n",
       "      <td>6.0032</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4332</th>\n",
       "      <td>2011-10-12 13:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>22.14</td>\n",
       "      <td>88</td>\n",
       "      <td>15.0013</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9506</th>\n",
       "      <td>2012-09-19 11:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24.60</td>\n",
       "      <td>43</td>\n",
       "      <td>16.9979</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7526</th>\n",
       "      <td>2012-05-12 23:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.78</td>\n",
       "      <td>56</td>\n",
       "      <td>6.0032</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6471</th>\n",
       "      <td>2012-03-06 21:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.12</td>\n",
       "      <td>49</td>\n",
       "      <td>12.9980</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2454</th>\n",
       "      <td>2011-06-10 04:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27.06</td>\n",
       "      <td>78</td>\n",
       "      <td>11.0014</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9484</th>\n",
       "      <td>2012-09-18 13:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>28.70</td>\n",
       "      <td>74</td>\n",
       "      <td>39.0007</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2667</th>\n",
       "      <td>2011-06-19 01:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>28.70</td>\n",
       "      <td>65</td>\n",
       "      <td>6.0032</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8164 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                datetime  season  holiday  workingday  weather   temp   \n",
       "3738 2011-09-06 17:00:00       3        0           1        2  22.14  \\\n",
       "3991 2011-09-17 08:00:00       3        0           0        2  18.86   \n",
       "8608 2012-08-01 01:00:00       3        0           1        1  27.06   \n",
       "4332 2011-10-12 13:00:00       4        0           1        3  22.14   \n",
       "9506 2012-09-19 11:00:00       3        0           1        1  24.60   \n",
       "...                  ...     ...      ...         ...      ...    ...   \n",
       "7526 2012-05-12 23:00:00       2        0           0        1  23.78   \n",
       "6471 2012-03-06 21:00:00       1        0           1        1  13.12   \n",
       "2454 2011-06-10 04:00:00       2        0           1        1  27.06   \n",
       "9484 2012-09-18 13:00:00       3        0           1        2  28.70   \n",
       "2667 2011-06-19 01:00:00       2        0           0        2  28.70   \n",
       "\n",
       "      humidity  windspeed  day  hour  month  \n",
       "3738        88    26.0027    6    17      9  \n",
       "3991        77    16.9979   17     8      9  \n",
       "8608        83     6.0032    1     1      8  \n",
       "4332        88    15.0013   12    13     10  \n",
       "9506        43    16.9979   19    11      9  \n",
       "...        ...        ...  ...   ...    ...  \n",
       "7526        56     6.0032   12    23      5  \n",
       "6471        49    12.9980    6    21      3  \n",
       "2454        78    11.0014   10     4      6  \n",
       "9484        74    39.0007   18    13      9  \n",
       "2667        65     6.0032   19     1      6  \n",
       "\n",
       "[8164 rows x 11 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('bins', KBinsDiscretizer(n_bins=10))\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_transformer = ColumnTransformer([\n",
    "    ('one_encode', OneHotEncoder(),['season', 'holiday', 'workingday', 'weather', 'hour', 'day','month',]), #One Hot Encoder is for categorical/discrete variables to turn them into binary matrices \n",
    "    ('pipeline', pipeline, ['temp', 'humidity', 'windspeed',]), #you can add casual and registered, windspeed might be easier to just drop?\n",
    "    ('pass', 'passthrough'),\n",
    "       \n",
    "]\n",
    ",remainder = \"drop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_pipeline = Pipeline([\n",
    "    ('column_transformer', column_transformer),\n",
    "    (\"model\", LinearRegression())\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_train_transformed \u001b[39m=\u001b[39m column_transformer\u001b[39m.\u001b[39;49mfit_transform(X_train,y_train)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py:723\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[39m# set n_features_in_ attribute\u001b[39;00m\n\u001b[1;32m    722\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_n_features(X, reset\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 723\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_transformers()\n\u001b[1;32m    724\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_column_callables(X)\n\u001b[1;32m    725\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_remainder(X)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py:398\u001b[0m, in \u001b[0;36mColumnTransformer._validate_transformers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformers:\n\u001b[1;32m    396\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 398\u001b[0m names, transformers, _ \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformers)\n\u001b[1;32m    400\u001b[0m \u001b[39m# validate names\u001b[39;00m\n\u001b[1;32m    401\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_names(names)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "#X_train_transformed = column_transformer.fit_transform(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_poly = LinearRegression()\n",
    "m_ridge = Ridge(alpha=1, random_state=14)\n",
    "m_lasso = Lasso(alpha=1, random_state=14)\n",
    "m_elastic_net = ElasticNet(alpha=1, l1_ratio=.5,\n",
    "                           random_state=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_lasso.fit(X_train_transformed, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_lasso = m_lasso.predict(X_train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_lasso.score(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I do not get this\n",
    "#m_lasso.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_pd = pd.DataFrame(X_train_transformed, columns=general_pipeline[:-1].get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general_pipeline.fit(X_train_pd,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#column_transformer.get_feature_names_out()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "\n",
    "model.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#niceeee score\n",
    "general_pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
